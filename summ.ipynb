{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":32267,"sourceType":"datasetVersion","datasetId":24984}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading in Data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Define the path to the 'BBC News Summary' folder\nbase_folder = '/kaggle/input/bbc-news-summary/BBC News Summary'\n\n# Initialize empty lists to store the data\narticle_texts = []\nsummaries = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loop through the subfolders (001, 002, etc.) inside 'News Articles' and 'Summaries'\nfor folder_name in os.listdir(os.path.join(base_folder, 'News Articles')):\n\n    # Construct the paths to the TXT files in 'News Articles' and 'Summaries' folders\n    article_folder = os.path.join(base_folder, 'News Articles', folder_name)\n    summary_folder = os.path.join(base_folder, 'Summaries', folder_name)\n\n    # Loop through the TXT files in the current subfolder\n    for file_name in os.listdir(article_folder):\n        # Construct the full paths to the TXT files\n        article_file = os.path.join(article_folder, file_name)\n        summary_file = os.path.join(summary_folder, file_name)\n        \n        # Check if the files exist\n        if os.path.exists(article_file) and os.path.exists(summary_file):\n            try:\n                # Read the text and summary data from the TXT file with UTF-8 encoding\n                article_df = open(article_file, 'r', encoding='utf-8').read()\n                summary_df = open(summary_file, 'r', encoding='utf-8').read()\n                \n                # Append the article text and summary to the respective lists\n                article_texts.append(article_df)\n                summaries.append(summary_df)\n            except UnicodeDecodeError:\n                # Handle files with incorrect encoding\n                print(f\"File with incorrect encoding: {article_file}\")\n                continue\n\n# Create a Pandas DataFrame with the collected data\ndata = {'Article Text': article_texts, 'Summary': summaries}\ndf = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T22:57:45.740117Z","iopub.execute_input":"2023-10-30T22:57:45.740986Z","iopub.status.idle":"2023-10-30T22:57:52.153392Z","shell.execute_reply.started":"2023-10-30T22:57:45.740951Z","shell.execute_reply":"2023-10-30T22:57:52.152101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load data from a CSV file\ndata = df\n\n# Ensure the column names match your DataFrame's column names\ndata.columns = ['Article Text', 'Summary']\n\n# Split data into training, validation, and test sets\ntrain_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n\n# Now you have three datasets: train_data, val_data, and test_data\n# You can proceed with preprocessing or model training","metadata":{"execution":{"iopub.status.busy":"2023-10-30T22:58:02.180454Z","iopub.execute_input":"2023-10-30T22:58:02.181493Z","iopub.status.idle":"2023-10-30T22:58:03.176261Z","shell.execute_reply.started":"2023-10-30T22:58:02.181454Z","shell.execute_reply":"2023-10-30T22:58:03.175465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Data for Training","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\nimport torch\nfrom tqdm import tqdm  # Import tqdm\n\n# Initialize the T5 tokenizer and model\ntokenizer = T5Tokenizer.from_pretrained('t5-small')\nmodel = T5ForConditionalGeneration.from_pretrained('t5-small')\n\ndef convert_to_features(index, row):\n    # Encode the articles and summaries to the format expected by T5\n    input_encodings = tokenizer(row['Article Text'], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n    target_encodings = tokenizer(row['Summary'], truncation=True, padding='max_length', max_length=150, return_tensors=\"pt\")\n    \n    return {\n        'input_ids': input_encodings['input_ids'],\n        'labels': target_encodings['input_ids']\n    }\n\n\n# Convert your data batches to features with progress bar\ntrain_features = [convert_to_features(index, row) for index, row in tqdm(train_data.iterrows(), total=len(train_data), desc='Processing Training Data')]\nval_features = [convert_to_features(index, row) for index, row in tqdm(val_data.iterrows(), total=len(val_data), desc='Processing Validation Data')]","metadata":{"execution":{"iopub.status.busy":"2023-10-30T22:58:10.625744Z","iopub.execute_input":"2023-10-30T22:58:10.62646Z","iopub.status.idle":"2023-10-30T22:58:47.941861Z","shell.execute_reply.started":"2023-10-30T22:58:10.626424Z","shell.execute_reply":"2023-10-30T22:58:47.940913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"markdown","source":"## 1. Create a Dataset Class:\nDefine a PyTorch dataset class to manage your data.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass TextSummarizationDataset(Dataset):\n    def __init__(self, features):\n        self.features = features\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return self.features[idx]\n\n# Instantiate the dataset class with your data\ntrain_dataset = TextSummarizationDataset(train_features)\nval_dataset = TextSummarizationDataset(val_features)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T22:59:09.513948Z","iopub.execute_input":"2023-10-30T22:59:09.514696Z","iopub.status.idle":"2023-10-30T22:59:09.520202Z","shell.execute_reply.started":"2023-10-30T22:59:09.514665Z","shell.execute_reply":"2023-10-30T22:59:09.519258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Create Data Loaders:\nSet up data loaders to handle batching of data during training and validation.","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T22:58:59.494521Z","iopub.execute_input":"2023-10-30T22:58:59.495592Z","iopub.status.idle":"2023-10-30T22:58:59.499984Z","shell.execute_reply.started":"2023-10-30T22:58:59.495552Z","shell.execute_reply":"2023-10-30T22:58:59.49898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Set Up Training Loop:\nDefine the optimizer, loss function (if needed), and set up the training loop.","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nfrom tqdm import tqdm\nimport torch\n\n# Specify the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Transfer the model to the GPU\nmodel = model.to(device)\n\n# Define the optimizer\noptimizer = optim.Adam(model.parameters(), lr=5e-4)\n\n# Specify the number of epochs\nnum_epochs = 3\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    total_train_loss = 0\n    for batch in tqdm(train_dataloader, desc=f'Training Epoch {epoch + 1}'):\n        optimizer.zero_grad()\n        inputs = batch['input_ids'].squeeze(dim=1).to(device)\n        labels = batch['labels'].squeeze(dim=1).to(device)\n        outputs = model(input_ids=inputs, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        total_train_loss += loss.item()\n\n    # Validation loop\n    model.eval()\n    total_val_loss = 0\n    with torch.no_grad():\n        for batch in tqdm(val_dataloader, desc=f'Validation Epoch {epoch + 1}'):\n            inputs = batch['input_ids'].squeeze(dim=1).to(device)\n            labels = batch['labels'].squeeze(dim=1).to(device)\n            outputs = model(input_ids=inputs, labels=labels)\n            total_val_loss += outputs.loss.item()\n\n    print(f'Epoch {epoch + 1}, Training Loss: {total_train_loss / len(train_dataloader)}, Validation Loss: {total_val_loss / len(val_dataloader)}')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T22:59:30.375081Z","iopub.execute_input":"2023-10-30T22:59:30.375456Z","iopub.status.idle":"2023-10-30T23:04:07.113578Z","shell.execute_reply.started":"2023-10-30T22:59:30.375426Z","shell.execute_reply":"2023-10-30T23:04:07.1125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained('Model-Files')\ntokenizer.save_pretrained('Model-Files')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T23:13:51.478696Z","iopub.execute_input":"2023-10-30T23:13:51.479657Z","iopub.status.idle":"2023-10-30T23:13:51.853193Z","shell.execute_reply.started":"2023-10-30T23:13:51.479621Z","shell.execute_reply":"2023-10-30T23:13:51.852459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test on a new summary here:","metadata":{}},{"cell_type":"code","source":"# Example of generating a summary\ndef summarize(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n    summary_ids = model.generate(\n    inputs['input_ids'], \n    max_length=150, \n    num_beams=4, \n    length_penalty=2.0, \n    early_stopping=True, \n    no_repeat_ngram_size=2  # This parameter can help reduce repetition\n).to(device)\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary\n\n# Use the function to summarize a new article\narticle= '''\nTitle: \"Tech Trends Shaping the Future: Innovations, Challenges, and Opportunities\"\n\nIntroduction\n\nTechnology has become an integral part of our daily lives, revolutionizing the way we work, communicate, and interact with the world around us. With each passing year, we witness remarkable advancements in the tech industry that not only change the way we live but also offer new avenues for growth and development. In this article, we will explore some of the most significant tech trends that are shaping the future, as well as the challenges and opportunities they present.\n\n1. Artificial Intelligence (AI) and Machine Learning\n\nArtificial intelligence and machine learning have seen unprecedented growth in recent years. These technologies have the potential to transform industries such as healthcare, finance, and transportation. AI-powered chatbots, autonomous vehicles, and predictive analytics are just a few examples of how AI and machine learning are changing the way we work and live. However, ethical concerns, data privacy issues, and the need for responsible AI development are challenges that must be addressed as these technologies continue to advance.\n\n2. Internet of Things (IoT)\n\nThe Internet of Things is connecting everyday objects and devices to the internet, enabling them to communicate and share data. From smart thermostats and wearable fitness trackers to smart cities' infrastructure, IoT is enhancing efficiency, convenience, and sustainability. However, the massive influx of data generated by IoT devices poses security and privacy concerns, requiring robust cybersecurity measures to protect sensitive information.\n\n3. 5G Technology\n\nThe rollout of 5G networks is set to revolutionize connectivity, offering faster speeds and lower latency. This will unlock new possibilities for applications such as augmented reality (AR), virtual reality (VR), and the Internet of Things. The increased bandwidth will pave the way for innovations in telemedicine, autonomous vehicles, and remote work. However, concerns about the deployment of 5G infrastructure and potential health risks associated with prolonged exposure to high-frequency electromagnetic radiation are subjects of ongoing debate.\n\n4. Cybersecurity\n\nAs technology continues to advance, the threat landscape in the digital world is also evolving. Cybersecurity is a critical concern for individuals, businesses, and governments. The rise of sophisticated cyberattacks, ransomware incidents, and data breaches underscores the need for robust security measures. Organizations must invest in cybersecurity technologies and develop proactive strategies to protect sensitive data and infrastructure.\n\n5. Green Technology and Sustainability\n\nThe tech industry is increasingly focused on sustainability and environmental responsibility. Renewable energy sources, energy-efficient data centers, and eco-friendly products are at the forefront of this movement. As consumers become more environmentally conscious, companies are finding that sustainable practices are not only ethical but also profitable. Investing in green technology and adopting eco-friendly practices can lead to cost savings and a positive brand image.\n\n6. Remote Work and Collaboration Tools\n\nThe COVID-19 pandemic accelerated the adoption of remote work and collaboration tools. Video conferencing, project management software, and cloud-based services have become essential for businesses to maintain productivity and adapt to remote work environments. While remote work offers flexibility and accessibility, it also presents challenges related to employee well-being, cybersecurity, and maintaining a sense of company culture.\n\n7. Quantum Computing\n\nQuantum computing is on the horizon and has the potential to revolutionize computing as we know it. With the ability to perform complex calculations at speeds unattainable by classical computers, quantum computers could solve problems in fields like cryptography, drug discovery, and climate modeling. However, building and maintaining stable quantum systems remains a significant technological challenge.\n\nConclusion\n\nThe tech landscape is continually evolving, presenting both exciting opportunities and complex challenges. As we embrace innovations in artificial intelligence, IoT, 5G, cybersecurity, sustainability, remote work, and quantum computing, it is crucial to approach these developments with a thoughtful and ethical perspective. Balancing the potential for progress with responsible development and addressing the associated risks will be key to harnessing the full potential of technology in shaping our future. By staying informed and proactive, individuals, businesses, and society as a whole can navigate the ever-changing tech landscape with confidence and resilience.'''\nnew_summary = summarize(article)\nprint(new_summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T23:15:26.129766Z","iopub.execute_input":"2023-10-30T23:15:26.130159Z","iopub.status.idle":"2023-10-30T23:15:27.618388Z","shell.execute_reply.started":"2023-10-30T23:15:26.130129Z","shell.execute_reply":"2023-10-30T23:15:27.617301Z"},"trusted":true},"execution_count":null,"outputs":[]}]}